{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsim = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data(n, sims):\n",
    "    np.random.seed(1015033030)\n",
    "    \n",
    "    ids = []  # Generating simulation IDs\n",
    "    for i in range(sims):\n",
    "        ids.extend([i + 1] * n)\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    df['sim_id'] = ids\n",
    "\n",
    "    # Creating confounders\n",
    "    df['age'] = np.round(np.random.normal(65, 10, size=n * sims), 0)  \n",
    "    df['crcl_log'] = np.random.normal(np.log(110), 0.18, size=n * sims) - 0.005 * df['age']\n",
    "    df['crcl'] = np.exp(df['crcl_log'])\n",
    "    df['diabetes'] = np.random.binomial(n=1, p=st.logistic.cdf(-6.73 + 0.03 * df['crcl_log'] + 0.02 * df['age'] +\n",
    "                                                            0.0009 * df['age'] ** 2), size=n * sims)\n",
    "    df['insulin'] = np.where(df['diabetes']==1,\n",
    "                        np.random.binomial(n=1, p=st.logistic.cdf(-4.16 + 0.04 * df['crcl_log'] - 0.02 * df['age'] +\n",
    "                                                            0.0009 * df['age'] ** 2), size=n * sims),\n",
    "                             0)\n",
    "    df['lvef'] = np.random.beta(11, 7, size=n * sims)*100 - 0.06 * df['age']\n",
    "    df['smoking'] = np.random.binomial(n=1, p=.21, size=n * sims)\n",
    "    df['pvd'] = np.random.binomial(n=1, p=st.logistic.cdf(-5.62 + 0.03 * df['smoking'] - 0.02 * df['age'] +\n",
    "                                                            0.0009 * df['age'] ** 2), size=n * sims)\n",
    "    df['copd'] = np.random.binomial(n=1, p=st.logistic.cdf(-2.71 + 0.03 * df['smoking'] + 0.01 * df['pvd']), size=n * sims)\n",
    "\n",
    "    df['tvd_lmcad'] = st.betabinom.rvs(2, .4, .7, loc=0, size=n * sims, random_state=None) #nb 0=3vd only, 1=lmcad only, 2=both\n",
    "\n",
    "    # One-hot encoding\n",
    "    df['tvd'] = np.where(df['tvd_lmcad']==0, 1, 0)\n",
    "    df['lmcad'] = np.where(df['tvd_lmcad']==1, 1, 0)\n",
    "    df['both'] = np.where(df['tvd_lmcad']==2, 1, 0)\n",
    "\n",
    "    ## Define and run a function that generates anatomical SYNTAX scores\n",
    "    def sim_anat_syntax(tvd_lmcad):\n",
    "        \"\"\"simulate anatomic syntax scores from coronary disease type.\"\"\"\n",
    "        from zepid.sensitivity_analysis import trapezoidal\n",
    "\n",
    "        dummy_mat=np.stack([tvd_lmcad==0, tvd_lmcad==1, tvd_lmcad==2], axis=1)\n",
    "\n",
    "        tvd=trapezoidal(3,10,10,50, len(tvd_lmcad))\n",
    "        lmcad=trapezoidal(4,20,20,50, len(tvd_lmcad))\n",
    "        both=trapezoidal(7,10,30,60, len(tvd_lmcad))\n",
    "\n",
    "        return(dummy_mat[:,0]*tvd + dummy_mat[:,1]*lmcad + dummy_mat[:,2]*both)\n",
    "\n",
    "    df['syntax']= np.round(sim_anat_syntax(df['tvd_lmcad']))\n",
    "\n",
    "    ## Treatment allocation mechanism (True Propensity Score)\n",
    "    df['cabg_pr'] = st.logistic.cdf(-2.971\n",
    "                               + 0.049 * (df['age'] - 30)\n",
    "                               - 0.001 * (df['age'] - 30)**2\n",
    "                               + 0.212 * df['crcl_log']\n",
    "                               + 0.973 * np.where(df['crcl_log'] > np.log(100), 1, 0)\n",
    "                               - 0.386 * df['copd']\n",
    "                               # Treatment-assignment based on disease type\n",
    "                               + 1.973 * df['lmcad']\n",
    "                               + 2.973 * df['both']\n",
    "                               )\n",
    "    df['cabg'] = np.random.binomial(n=1, p=df['cabg_pr'], size=n*sims)\n",
    "\n",
    "    ## Potential outcomes\n",
    "    def syntax2020(age, crcl, lvef, copd, pvd, diabetes, insulin, smoking, tvd, lmcad, syntax, cabg):\n",
    "        return 1-np.exp(-0.243 *np.exp(0.99 * (0.72*age/10 - 0.07 * np.where(crcl<90, crcl ,90)/10 -0.31 * np.where(lvef<50, lvef, 50)/10 + 0.48 * copd + 0.73 * pvd + 0.20 * diabetes \n",
    "                    + 0.46 * insulin + 0.66 * smoking)\n",
    "                    - 0.4 * cabg * tvd - 0.08 * cabg * lmcad - 0.1 * (1 - cabg) * lmcad + .16 * (1-cabg) * (syntax - 29)/10 -2.80))\n",
    "    \n",
    "    df['prY1'] = df.apply(lambda row : syntax2020(age=row['age'], crcl=np.exp(row['crcl_log']), lvef=row['lvef'],\n",
    "                                copd=row['copd'], pvd=row['pvd'], diabetes=row['diabetes'],\n",
    "                                 insulin=row['insulin'], smoking=row['smoking'], tvd=row['tvd_lmcad']==0,\n",
    "                                 lmcad=row['tvd_lmcad']==1, syntax=row['syntax'],\n",
    "                                 cabg=1), axis = 1)\n",
    "\n",
    "    df['Y1'] = np.random.binomial(n=1, p=df['prY1'], size=n*sims)\n",
    "\n",
    "    df['prY0'] = df.apply(lambda row : syntax2020(age=row['age'], crcl=np.exp(row['crcl_log']), lvef=row['lvef'],\n",
    "                                copd=row['copd'], pvd=row['pvd'], diabetes=row['diabetes'],\n",
    "                                 insulin=row['insulin'], smoking=row['smoking'], tvd=row['tvd_lmcad']==0,\n",
    "                                 lmcad=row['tvd_lmcad']==1, syntax=row['syntax'],\n",
    "                                 cabg=0), axis = 1)\n",
    "\n",
    "    df['Y0'] = np.random.binomial(n=1, p=df['prY0'], size=n*sims)\n",
    "\n",
    "    df['Y'] = np.where(df['cabg'] == 1, df['Y1'], df['Y0'])  # causal consistency\n",
    "\n",
    "    df['true_cate'] = df['prY1'] - df['prY0']\n",
    "\n",
    "    df['pred_cate'] = df['true_cate']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_df = gen_data(nsim, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define functions for the true ARE and true ASREs (three stochastic implementations as described below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_true_are(df):\n",
    "    \"\"\"Compute true ARE from the true ps and the true cate\"\"\"\n",
    "    true_are = np.mean( ( (df.pred_cate<0) - df.cabg_pr)*df.true_cate)\n",
    "    return true_are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_true_r_asre(df, alpha):\n",
    "    \"\"\"Compute true uniform/random ASRE from the true ps and the true cate\n",
    "    alpha is the uniform/random parameter (bounded between 0 and 1) \"\"\"\n",
    "    df_temp = df\n",
    "    df_temp['p_x'] = np.repeat(alpha, len(df))\n",
    "    true_r_asre = np.mean( df_temp.p_x * ( (df_temp.pred_cate<0) - df_temp.cabg_pr)*df_temp.true_cate)\n",
    "    return true_r_asre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def syntax_iHR_ci(df, alpha=.05):\n",
    "    \"\"\"Get individualized HR and 1-alpha CI from SYNTAX 2020,\n",
    "    Uses table 2 predictive model coefficients and corresponding variance covariance matrix for the coefficients\"\"\"\n",
    "    \n",
    "    coef_mod2=np.array([0.99, -0.40, -0.08, -0.10, 0.16])\n",
    "    VCOV=np.array(  [[3.17E-03, -1.58E-04, -2.68E-04,2.56E-04,-3.78E-04],\n",
    "                     [-1.58E-04,1.53E-02,6.56E-03,6.48E-03,1.45E-04],\n",
    "                     [-2.68E-04,6.56E-03,1.68E-02,6.47E-03,1.62E-04],\n",
    "                     [2.56E-04,6.48E-03,6.47E-03,1.75E-02,-1.08E-03],\n",
    "                     [-3.78E-04,1.45E-04,1.62E-04,-1.08E-03,2.84E-03]])\n",
    "    \n",
    "    X_cabg=np.stack([np.repeat(99,len(df)), 1* (df.tvd_lmcad==0), 1* (df.tvd_lmcad==1), 0 * np.array(df.tvd_lmcad==1), 0 * (df.syntax-29) / 10]).T # NB PIs don't contribute as it cancel out\n",
    "    X_pci=np.stack([np.repeat(99,len(df)), 0* (df.tvd_lmcad==0), 0* (df.tvd_lmcad==1), 1 * np.array(df.tvd_lmcad==1), 1 * (df.syntax-29) / 10]).T # in the substraction (here set at 99)\n",
    "    X_diff=X_cabg-X_pci\n",
    "    log_iHR = X_diff.dot(coef_mod2)\n",
    "    \n",
    "    df_temp = df.copy()\n",
    "    df_temp['pred_hr'] = np.exp(log_iHR)\n",
    "    \n",
    "    log_iHR_se=X_diff.dot(VCOV).dot(X_diff.T).diagonal() # X * VCOV * Xtranspose\n",
    "    \n",
    "    temp = np.stack([log_iHR, log_iHR-st.norm.ppf(1-alpha/2)*log_iHR_se, log_iHR+st.norm.ppf(1-alpha/2)*log_iHR_se])\n",
    "    iHR_CI = np.exp(temp.T)\n",
    "    df_temp['iHR']= iHR_CI[:,0]\n",
    "    df_temp['iHR_lb']= iHR_CI[:,1]\n",
    "    df_temp['iHR_ub']= iHR_CI[:,2]\n",
    "    \n",
    "    significant = ((df_temp['iHR_lb']<1) == (df_temp['iHR_ub']<1))\n",
    "    \n",
    "    df_temp['significance'] = significant\n",
    "    \n",
    "    return df_temp\n",
    "\n",
    "def compute_true_ci_asre(df, alpha):\n",
    "    \"\"\"Compute true CI ASRE from the true ps and the true cate\"\"\"\n",
    "    df_temp = syntax_iHR_ci(df, alpha)\n",
    "    true_ci_asre = np.mean( df_temp.significance * ( (df_temp.pred_cate<0) - df_temp.cabg_pr)*df_temp.true_cate)\n",
    "    return true_ci_asre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def legit(x):\n",
    "    return .5 * np.log((x+1)/(1-x))\n",
    "\n",
    "def compute_true_cb_asre(df, alpha):\n",
    "    \"\"\"Compute true cognitive biais ASRE from the true ps and the true cate,\n",
    "    alpha is the cognitive biais parameter (bounded between 0 and 1) \"\"\"\n",
    "    df_temp = df\n",
    "    df_temp['p_x'] = (1 - np.abs( (df_temp['pred_cate']<0) - df_temp['cabg_pr']) ) ** legit(alpha)\n",
    "    true_cb_asre = np.mean( df_temp.p_x * ( (df_temp.pred_cate<0) - df_temp.cabg_pr)*df_temp.true_cate)\n",
    "    return true_cb_asre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run these functions on the large simulated dataframe ( `nsim` observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_are = compute_true_are(large_df)\n",
    "\n",
    "true_1_3_r_asre = compute_true_r_asre(large_df, 1/3)\n",
    "true_2_3_r_asre = compute_true_r_asre(large_df, 2/3)\n",
    "\n",
    "true_95_ci_asre = compute_true_ci_asre(large_df, .05)\n",
    "true_55_ci_asre = compute_true_ci_asre(large_df, .45)\n",
    "\n",
    "true_1_3_cb_asre = compute_true_cb_asre(large_df, 1/3)\n",
    "true_2_3_cb_asre = compute_true_cb_asre(large_df, 2/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.02944509194220231"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_are"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demonstration of how the asre_compute package works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masre_package\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mrule\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mttt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mps_predictors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpronostic_predictors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mctst_vrb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ARE'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_alphas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mprecision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "From a pandas dataframe, this program computes the Absolute Rule Effect (ARE) or cognitive biais Absolute Stochastic Rule Effect (ASRE) through A-learning and provides asymptotic 95% confidence intervals from M-estimation sandwich formula.\n",
       "\n",
       "Arguments\n",
       "----------\n",
       "\n",
       "- df: pandas dataframe with no missing values.\n",
       "- rule: column name for the rule as a string (random variable must be Bernoulli). \n",
       "- ttt: column name for the experimental treatment as a string (random variable must be Bernoulli). \n",
       "- y: column name for the outcome as a string (random variable can be either binary or continuous). \n",
       "- ps_predictors: list of column names (strings) for variables causing experimental treatment initiation e.g.propensity score predictors (random variables can be either binary or continuous). \n",
       "- pronostic_predictors: list of column names (strings) for variables causing the outcome e.g. prognosis predictors (random variables can be either binary or continuous). \n",
       "- ctst_vrb: list of column names (strings) for variables acting as treatment effect modifiers e.g. contrast variables (random variables can be either binary or continuous). \n",
       "- est = 'ARE': takes value 'ARE' or 'ASRE_cb'. When 'ARE' is passed, the program computes only the Absolute Rule Effect ; when 'ASRE_cb' is passed it computes the ARE and alpha-level cognitive biais ASRE with alpha provided below.\n",
       "- alpha = .5: alpha-level cognitive biais for ASRE used when est = 'ASRE_cb'.\n",
       "- n_alphas = 5: number of linearly spaced alphas computed on the plot wehn est='ASRE_cb'.\n",
       "- precision = 3: rounding of the printed ARE/ASRE and their 95% confidence intervals.\n",
       "\n",
       "\n",
       "Returns\n",
       "-------\n",
       "\n",
       "In a tuple, this program returns all parameters along their corresponding variance-covariance matrix.\n",
       "Parameters are provided in the following order.\n",
       "Estimator, Contrast intercept, Contrast coefficients, Prognostic intercept, Prognostic coefficients, Propensity score intercept, Propensity score coefficients.\n",
       "\n",
       "- When est = 'ARE', the estimator return is the ARE.\n",
       "The tuple returned is (parameters, VCV)\n",
       "\n",
       "- When est = 'ASRE_cb', the estimator return is the alpha-level cognitive biais ASRE with the alpha value provided as argument.\n",
       "The program also returns a plot of the ASRE at different levels of linealy spaced alphas as provided in the n_alpha argument.\n",
       "The tuple returned is (plot, parameters, VCV)\n",
       "\n",
       "\n",
       "Example\n",
       "-------\n",
       "\n",
       "plot, parameters, VCV = tools.asre_package(observational_dataframe, \n",
       "          rule = \"rule\",\n",
       "          ttt = \"cabg\",\n",
       "          y = \"Y\",\n",
       "          ps_predictors = [\"age\", \"crcl_log\", \"copd\", \"tvd\", \"lmcad\", \"both\"],\n",
       "          pronostic_predictors = [\"tvd\", \"lmcad\", \"both\", \"syntax\", \"age\", \"crcl\", \"diabetes\", \"insulin\", \"lvef\", \"smoking\", \"pvd\", \"copd\"],\n",
       "          ctst_vrb = ['syntax', 'tvd', 'lmcad'],\n",
       "          est='ASRE_cb', alpha = .5, n_alphas=5, precision=3)\n",
       "          \n",
       "Further implementation detail will be posted on https://github.com/fcgrolleau/Emulated-ITR\n",
       "Theoretical argument including extensive simulations will be posted on Arxiv soon.\n",
       "\u001b[0;31mFile:\u001b[0m      ~/opt/anaconda3/lib/python3.8/site-packages/asre_compute/tools.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from asre_compute import tools\n",
    "tools.asre_package?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply the package on the first 2000 patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARE = -0.03027  95% CI (-0.05635 to -0.00419)\n",
      "ASRE (cognitive biais 0.5) = -0.01339  95% CI (-0.04054 to -0.02)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-0127263d6725>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlarge_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rule'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlarge_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred_cate\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m tools.asre_package(large_df.iloc[:2000,], \n\u001b[0m\u001b[1;32m      3\u001b[0m           \u001b[0mrule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"rule\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0mttt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'cabg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Y\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mps_predictors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"age\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"crcl_log\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"copd\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tvd\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"lmcad\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"both\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/asre_compute/tools.py\u001b[0m in \u001b[0;36masre_package\u001b[0;34m(df, rule, ttt, y, ps_predictors, pronostic_predictors, ctst_vrb, est, alpha, n_alphas, precision)\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;32min\u001b[0m \u001b[0malphas\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m             \u001b[0mp_x_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mdf_temp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrule\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mps_pred\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mlegit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mVCV_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mV_cov_mat_fast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_temp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mttt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mps_predictors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpronostic_predictors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctst_vrb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_x_temp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mare_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpsi_hat_icpt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpsi_hat_coef\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphi_hat_icpt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphi_hat_coef\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma_hat_icpt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma_hat_coef\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0masre_hats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mp_x_temp\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf_temp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrule\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdf_temp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mttt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdf_temp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cate_hat\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0masre_ses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVCV_temp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/asre_compute/tools.py\u001b[0m in \u001b[0;36mV_cov_mat_fast\u001b[0;34m(df_temp, rule, ttt, y, ps_predictors, pronostic_predictors, ctst_vrb, p_x, are_hat, psi_hat_icpt, psi_hat_coef, phi_hat_icpt, phi_hat_coef, gamma_hat_icpt, gamma_hat_coef)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0;31m# Compute Lateral estimator from the sandwitch formula\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         Lat = M_jacob_inv(r_x = df_temp[rule],\n\u001b[0m\u001b[1;32m    436\u001b[0m           \u001b[0mttt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_temp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mttt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m           \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_temp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/asre_compute/tools.py\u001b[0m in \u001b[0;36mM_jacob_inv\u001b[0;34m(r_x, ttt, y, X_ctst, X_pr, X_ps, delta, ctst_icpt, ctst_coef, pr_icpt, pr_coef, ps_icpt, ps_coef, p_x)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 \u001b[0;31m## derivation wrt phi0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m                 \u001b[0mJacob\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpatient\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_ctst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_ctst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mX_pr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpatient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mJacob\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpatient\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_ctst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_ctst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m                 \u001b[0;31m## derivation wrt phi_s\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mReturn\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlength\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \"\"\"\n\u001b[0;32m--> 571\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "large_df['rule'] = large_df.pred_cate<0\n",
    "tools.asre_package(large_df.iloc[:2000,], \n",
    "          rule = \"rule\",\n",
    "          ttt = 'cabg', y = \"Y\",\n",
    "          ps_predictors = [\"age\", \"crcl_log\", \"copd\", \"tvd\", \"lmcad\", \"both\"],\n",
    "          pronostic_predictors = [\"tvd\", \"lmcad\", \"both\", \"syntax\", \"age\", \"crcl\", \"diabetes\", \"insulin\", \"lvef\", \"smoking\", \"pvd\", \"copd\"],\n",
    "          ctst_vrb = ['syntax', 'tvd', 'lmcad'],\n",
    "          est='ASRE_cb', alpha = .5, n_alphas=10, precision=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
